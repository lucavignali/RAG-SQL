{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff86475-5867-44b3-b9a3-69203ee639b1",
   "metadata": {},
   "source": [
    "# Network Genius: On-demand observability of Network data using Langchain SQL Agent, Athena and Amazon Bedrock \n",
    "\n",
    "**Info.**  \n",
    "The current lab1 workshop is part of a solution called Network Genius. Network Genius is a multi-scenario solution that includes features like network Configuration generation, multi-db observability, etc. The query generation feature is part of Network_Genius_v0. \n",
    "\n",
    "In this notebook, we will create a conversational agent that allows you to ask questions about your network data. In a couple of seconds, as a network operations team, you will be able to drill-down, assess the health-check of your network resources, and build on-the-fly network Key Performance Indicators without predefining them.\n",
    "\n",
    "In this lab, you will be doing a drill down process for network failures as well as for the impacted customers. \n",
    "\n",
    "The network drill down process follows these steps:\n",
    "\n",
    "- Identify how many active users are in California\n",
    "\n",
    "- assessing what are the reasons of failures in California and expecting that the model will list and explain them in term of drop calls, white communications, etc. \n",
    "\n",
    "- from those reasons of failure in California, we select the code 38 which is about Network out of order and ask about the associated top 10 cells.\n",
    "\n",
    "- Now that we have the cells IDs with release 38, we want to know the 10 cells, that are congested based on Radio Access Networks. Release codes are not all the time indicating real failure. Important to rely on key performance for failure. \n",
    "\n",
    "- With the identified congested cells, we want to identify the 10 most impacted customers in California.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a375c3b-72db-4d34-93d2-f04a1baccf0f",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881faa73-ad4b-48b2-a12e-a679a97d8717",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install required packages\n",
    "\n",
    "Run the cell below to install required Python dependencies. You may see some errors - you can safely ignore these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8ab9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet\n",
    "!pip install langchain_experimental --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e175b0-b433-48a5-819a-fa669e6d669e",
   "metadata": {},
   "source": [
    "### Set variables for our environment\n",
    "\n",
    "Replace *\\<values in angle brackets\\>* with the correct value from your CloudFormation Outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a7021-b91c-40d6-b9a2-40df839aad70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AWS_REGION = \"us-west-2\"\n",
    "ATHENA_RESULTS_BUCKET = \"<ATHENA_RESULTS_BUCKET>\" # Get this from CFN outputs\n",
    "NETWORK_DB=\"network-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67922e-d515-4802-b37d-e6d5dd394d29",
   "metadata": {},
   "source": [
    "### Set up and test Bedrock access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa9b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#SQLAlchemy is the Python SQL toolkit and Object Relational Mapper that gives application developers the full power and flexibility of SQL\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain import PromptTemplate,SagemakerEndpoint,SQLDatabase, LLMChain\n",
    "\n",
    "#Chain for interacting with SQL Database.\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "#additional Lanchain modules which are being used throughout the notebook\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_experimental.sql import SQLDatabaseSequentialChain\n",
    "\n",
    "from langchain.chains.api.prompt import API_RESPONSE_PROMPT\n",
    "from langchain.chains import APIChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.api import open_meteo_docs\n",
    "\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e55ca5-0a14-4751-b0a9-06580d8b33ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#here we will import langhcain module which is being used with claude anthropic LLM which will we will use - hosted on Amazon Bedrock\n",
    "from langchain.chat_models import ChatAnthropic as Anthropic\n",
    "import anthropic\n",
    "from langchain.chat_models.bedrock import BedrockChat\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa463eee-682f-4d22-a15b-5e297d97b67f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The AWS SDK for Python (Boto3) provides a Python API for AWS infrastructure services. Using the SDK for Python, you can build applications on top of Amazon S3, Amazon EC2, Amazon DynamoDB, and more.\n",
    "session = boto3.Session()\n",
    "session._loader.search_paths.extend([\".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2fa1c-66d3-412b-98fb-c83aa63553ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#using bedrock runtime api to invoke the claude instant model \n",
    "#further guidance : https://docs.aws.amazon.com/bedrock/latest/userguide/api-methods-run-inference.html\n",
    "\n",
    "max_tokens_to_sample = 4096 \n",
    "temperature = 0.0\n",
    "stop_sequences = [\"Human\", \"Question\", \"Customer\", \"Guru\", \"</s>\"]\n",
    "\n",
    "boto3_bedrock = session.client(\"bedrock-runtime\", AWS_REGION)\n",
    "\n",
    "json_obj = {\"prompt\": \"\"\"\n",
    "Human: you are an expert Telco business analysts\n",
    "Assistant: \n",
    "\"\"\",\n",
    "                \"max_tokens_to_sample\": max_tokens_to_sample,\n",
    "                \"temperature\": temperature,\n",
    "                \"stop_sequences\": stop_sequences\n",
    "        }\n",
    "payload = json.dumps(json_obj)\n",
    "boto3_bedrock.invoke_model(\n",
    "            modelId= \"anthropic.claude-instant-v1\",\n",
    "            contentType= \"application/json\",\n",
    "            accept= \"application/json\",\n",
    "            body=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509afbb1-a7f4-465e-86c2-feefb54e53e7",
   "metadata": {},
   "source": [
    "## Set up database chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e0a8f-65ae-42d2-a338-a4f8b2b5c392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint = \"anthropic.claude-instant-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734dd80-1a99-46d8-a9e2-583de0eefe9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = BedrockChat(model_id=endpoint, client=boto3_bedrock, model_kwargs={\"temperature\":0.0, \"max_tokens_to_sample\": 4096})\n",
    "#llm = Bedrock(model_id=endpoint, client=boto3_bedrock, model_kwargs={\"temperature\":0.0, \"max_tokens_to_sample\": 4096})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ed9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## we will use sqlalchemy to invoke athena as our database engine for the sql queries to be executed on Amazon S3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "## athena variables\n",
    "connathena = f\"athena.{AWS_REGION}.amazonaws.com\"\n",
    "portathena = '443'\n",
    "schemaathena = NETWORK_DB\n",
    "\n",
    "s3stagingathena=f's3://{ATHENA_RESULTS_BUCKET}/'\n",
    "wkgrpathena='primary'\n",
    "\n",
    "connection_string = f\"awsathena+rest://@{connathena}:{portathena}/{schemaathena}?s3_staging_dir={s3stagingathena}/&work_group={wkgrpathena}\"\n",
    "\n",
    "##  Create the athena  SQLAlchemy engine\n",
    "engine_athena = create_engine(connection_string, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df53477-fcd6-4b38-a285-ecab518575e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine_athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e0882-44db-47f1-ac38-6c2c0b252114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dbathena = SQLDatabase(engine_athena)\n",
    "gdc = [schemaathena] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6c3a1-1dd0-4b87-889d-7cb0dd04586e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list of tables which are exposed by the AWS Glue data catalog for athena to query\n",
    "dbathena.get_usable_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a666419-d803-43d1-9464-955c0759417b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we will parse the AWS glue data catalog so we can store the metadata as table info so we can push it via the prompt \n",
    "#to provide the relevant context for our model to understand which tables should  be used when constructing the SQL queries.\n",
    "import boto3\n",
    "def parse_catalog_tables():\n",
    "    # Connect to Glue catalog\n",
    "    # Get metadata of redshift serverless tables\n",
    "    tables_and_columns = []\n",
    "    # Define Glue client\n",
    "    glue_client = boto3.client('glue')\n",
    "    for db in gdc:  # Assuming gdc is a list of database names\n",
    "        response = glue_client.get_tables(DatabaseName=db)\n",
    "        for table in response['TableList']:\n",
    "            table_name = table['Name']\n",
    "            for column in table['StorageDescriptor']['Columns']:\n",
    "                column_name = column['Name']\n",
    "                # Remove the prefix if it exists\n",
    "                if table_name.startswith(\"telecom_data_fabric_dbt_dan_\"):\n",
    "                    table_name = table_name[len(\"telecom_data_fabric_dbt_dan_\"):]\n",
    "                tables_and_columns.append(f'{table_name}|{column_name}')\n",
    "    # Return the list as a newline-separated string\n",
    "    return '\\n'.join(tables_and_columns)\n",
    "# Example usage:\n",
    "gdc = [schemaathena]  # Replace with your list of database names\n",
    "glue_catalog = parse_catalog_tables()\n",
    "print(glue_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125ea88-dc0c-4e8b-99a9-128f32fec587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# templates is the list of the different prompt_template you are testing. You can add several ones and select the one to use in the function chain as following chain = make_chain(query, templates[1])\n",
    "templates = {\n",
    " 1: \"\"\"\n",
    "    Given an input question, create a syntactically correct {dialect} query to run.\n",
    "    Return the well formatted SQL query in the answer with the markdown format\n",
    "    Only use the following tables:\n",
    "\n",
    "    {table_info}\n",
    "\n",
    "    Question: {input} \"\"\",\n",
    " 2: \"\"\" \"\"\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3a550-36ee-4825-b7f6-318f402a4955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqldbchain import SQLDatabaseChain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7038ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#using lancghcain - we are orchestrating a flow where:\n",
    "# user is generating a question->LLM translating from english to SQL -> athena triggering sql on the s3 ->athena brings back the results \n",
    "def make_chain(query, template):\n",
    "    PROMPT_sql = PromptTemplate(\n",
    "            input_variables=[\"input\", \"table_info\", \"dialect\"], template=template\n",
    "        )\n",
    "\n",
    "    return SQLDatabaseChain2.from_llm(llm, dbathena, prompt=PROMPT_sql, verbose=True)\n",
    "    \n",
    "#define a function that infers the channel/database/table and sets the database for querying\n",
    "def run_query(query, template):         \n",
    "    db_chain = make_chain(query, template)\n",
    "    response=db_chain.run(query=query, table_names_to_use=dbathena.get_usable_table_names())\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df500f20-a455-489b-94ae-098ffbe2b620",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run queries\n",
    "\n",
    "Try the queries below by uncommenting the one you would like to try and then executing the cell sequence.\n",
    "\n",
    "Note: You may get some errors for some queries, as the LLM we are using may not always get the SQL query right. If this happens, try executing the query again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b887e-2e20-4c29-9524-beffb914c09c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# identify how many active users in California\n",
    "query = \"How many active users in California?\"\n",
    "\n",
    "# assessing what are the reasons of failures in california and expecting that the model will list and explain them in term of drop calls, white communications, etc. \n",
    "#query = \"List the top 3 reasons of failures in California with their descriptions.\"\n",
    "\n",
    "# from those reasons of failure, we select 38 which is about Network out of order and ask about the associated top 10 cells.\n",
    "#query = \"What are the top cells having release cause 38 as a release code in California?\"\n",
    "\n",
    "# now that we have the cells IDs with release 38, we want to know the 10 cells, that are congested based on Radio Access Networks. Release code are not all the time indicating real failure. Important to rely on key performance for failure. \n",
    "#query = \"What are the top 10 cells that are congested in Califorina, taking into account the PRB utilisation and the RRC connection?\" \n",
    "\n",
    "# with the identified congested cells, we want to identify the 10 most impacted customers in California.  \n",
    "# query = \"List the 10 most impacted MSISDN by congestion in California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be10d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is just to show you what was built within the chain and the several parameters you might need to customize for your use case\n",
    "chain = make_chain(query, templates[1])\n",
    "print (chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5008bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response =  run_query(query, templates[1])"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
